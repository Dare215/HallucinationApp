# HallucinationApp: AI Hallucination Correction Assistant

**Author:** Darious Brown  
**GitHub:** [Dare215](https://github.com/Dare215)  
**Email:** dariousbrown3@icloud.com  

## 1) Project Overview
HallucinationApp is an AI-powered application designed to detect and correct hallucinations generated by large language models (LLMs).  
Using a fine-tuned GPT-3.5 model, the app provides corrected outputs with confidence scores, compares responses to external models, and delivers a user-friendly interface for real-time interaction.

## 2) Key Features
- **Hallucination Detection:** Identify factually inaccurate or fabricated LLM outputs.
- **Fine-Tuned GPT Model:** Optimized for logical correction tasks.
- **Confidence Scoring:** Uses fuzzy string matching to measure similarity and reliability.
- **Response Comparison:** Allows cross-checking with other AI models.
- **Real-Time Interface:** Built with Streamlit for instant corrections.

## 3) Dataset & Model
- **Fine-Tuned Model:** `ft:gpt-3.5-turbo-0125:dares-apis:hallucination-logical-v1:BvwmRqwc`
- **Training Data:** Curated question-answer pairs with verified factual responses.
- **Tech Stack:**  
  - OpenAI API (fine-tuning)  
  - Streamlit  
  - FuzzyWuzzy / RapidFuzz  
  - Python 3.10+

## 4) Project Structure
```
HallucinationApp/
│── HallucinationsApp.ipynb          # Development & testing notebook
│── main.py                           # Streamlit application
│── hallucination_dataset.jsonl       # Fine-tuning dataset
│── edfeadb0-5460-4e79-8bde-8070a0424f9c.png # App logo
│── README.md                         # Documentation
```

## 5) How to Run

### Option A — Python / Terminal
```bash
# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate    # Windows

# Install dependencies
pip install -r requirements.txt

# Run Streamlit app
streamlit run main.py
```

### Option B — PyCharm
1. Open folder in PyCharm  
2. Configure Python interpreter (point to `.venv`)  
3. Install dependencies from `requirements.txt`  
4. Run the Streamlit app

## 6) Results Summary
- Detected and corrected hallucinations in AI-generated responses.
- Provided confidence percentages for each correction.
- Enabled side-by-side comparison with external AI models.
- Demonstrated improved confidence scores over repeated interactions.

## 7) Ethical Considerations
- Avoid misuse in creating misleading or false content.
- Ensure factual accuracy in sensitive domains (health, finance, law).
- Maintain transparency with end-users about AI limitations.

## 8) Future Enhancements
- Expand to multi-sentence and multi-paragraph documents.
- Benchmark against multiple AI models for accuracy.
- Integrate into domain-specific tools (medical, financial).

## 9) License
MIT License — Free to use with attribution.
